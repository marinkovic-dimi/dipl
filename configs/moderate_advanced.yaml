project_name: "klasifikator"
version: "1.0.0"
experiment_name: "moderate_advanced_stratified_dropout"

data:
  raw_data_path: "data/oglasi_za_treniranje.json"
  processed_data_dir: "data/processed"

  text_column: "text"
  class_column: "group_id"
  clean_text_column: "clean_text"

  max_samples: 10000000
  min_samples_per_class: 100
  max_samples_per_class: 1000000
  remove_ostalo_groups: false
  ostalo_groups_file: "data/ostalo-grupe.csv"

  val_size: 0.15
  test_size: 0.15
  random_state: 42

tokenization:
  vocab_size: 15000
  max_length: 96
  min_frequency: 2
  special_tokens:
    - "[PAD]"
    - "[CLS]"
    - "[UNK]"
    - "[SEP]"
    - "[MASK]"
  use_cached_tokenizer: true
  tokenizer_cache_dir: "cache/tokenizers"
  use_tokenized_cache: true
  tokenized_cache_dir: "cache/tokenized_datasets"

model:
  embedding_dim: 384
  num_heads: 8
  num_layers: 3
  ff_dim: 1024

  dropout_rate: 0.15

  embedding_dropout: 0.1      
  attention_dropout: 0.15     
  ffn_dropout: 0.15           
  dense_dropout: 0.25         
  pooling_strategy: "attention" 
  label_smoothing: 0.1          
  learning_rate: 0.0003
  weight_decay: 0.01
  batch_size: 128
  epochs: 20

  top_k: 5

balancing:
  strategy: "adaptive"

  target_threshold: 3000
  target_threshold_small: 250
  increase_factor: 0.15
  decrease_factor: 0.5
  decrease_factor_small: 0.5

  tier_limits:
    small: 100
    medium: 1000
    large: 5000
    xlarge: 15000
    xxlarge: 40000
    max: 100000

training:
  save_dir: "experiments"
  model_name: "klasifikator_moderate_advanced"
  save_best_only: true
  patience: 7
  monitor: "val_loss"
  mode: "min"

  reduce_lr_factor: 0.5
  reduce_lr_patience: 3
  min_lr: 0.000001

  log_level: "INFO"
  log_to_file: true
  log_dir: "logs"

  checkpoint_freq: "epoch"
  save_frequency: 1

wandb:
  enabled: true
  project: "klasifikator"
  entity: null
  name: "moderate_advanced_stratified_dropout"
  tags:
    - "transformer"
    - "serbian"
    - "advanced-dropout"
    - "stratified-regularization"
  notes: "Advanced config with stratified dropout strategy: 10% embedding, 15% attention/ffn, 25% dense. Effective dropout: 51.2%. Includes label_smoothing fix, reduced complexity, faster LR, larger val set."
  log_model: true
  log_gradients: false
  log_frequency: 100
  save_code: true
